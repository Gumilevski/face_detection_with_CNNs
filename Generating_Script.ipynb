{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import sys\n",
    "import csv\n",
    "import numpy as np\n",
    "import random\n",
    "import cv2\n",
    "import math\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dir_if_not_exist(directory):\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_UMD(image_dir, anno_dir, train_size, test_size):\n",
    "    anno_file = os.path.join(anno_dir, 'umdfaces_batch3_ultraface.csv')\n",
    "    dataset = []\n",
    "    \n",
    "    num_train_test_size = train_size + test_size \n",
    "    \n",
    "    count = 0\n",
    "    with open(anno_file) as csvfile:\n",
    "        readCSV = csv.reader(csvfile, delimiter=',')\n",
    "        next(readCSV)\n",
    "        for row in readCSV:\n",
    "            per_data_info = []\n",
    "            \n",
    "            img_name = row[1]\n",
    "            face_x = row[4]\n",
    "            face_y = row[5]\n",
    "            face_width = row[6]\n",
    "            face_height = row[7]\n",
    "            \n",
    "            per_data_info.append(img_name)\n",
    "            per_data_info.append(face_x)\n",
    "            per_data_info.append(face_y)\n",
    "            per_data_info.append(face_width)\n",
    "            per_data_info.append(face_height)\n",
    "            \n",
    "            if count % 500 == 0:\n",
    "                print(count)\n",
    "            \n",
    "            count += 1\n",
    "            dataset.append(per_data_info)\n",
    "            if(count < num_train_test_size):\n",
    "                continue\n",
    "            break\n",
    "            \n",
    "    \n",
    "    csvfile.close()\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cначала ответами для изображений были координаты левой верхней вершины ограничительной рамки и \n",
    "# ширина и выcота этой рамки (функция generate_images_and_csv), но позже было принято решение заменить \n",
    "# ширину и высоту на координаты правой нижней вершины ограничительной рамки (функция new_csv), тем самым \n",
    "# мы добились большей однородности ответов (в данном случае под однородностью понимается то, \n",
    "# что все компоненты ответов – части координат некоторого пикселя)\n",
    " \n",
    "def generate_images_and_csv (image_dir, save_images_dir, save_csv, dataset, start_idx, data_size):\n",
    "    csv_data = [['id', 'x', 'y', 'w', 'h']]\n",
    "\n",
    "    for i in range(start_idx, start_idx + data_size):\n",
    "        per_data_info = dataset[i]\n",
    "        full_name = per_data_info[0]\n",
    "        index_of_slash = full_name.find('/')\n",
    "        img_name = full_name[index_of_slash+1:]\n",
    "        folder_name = img_name[:index_of_slash]\n",
    "        x = int(float(per_data_info[1]))\n",
    "        y = int(float(per_data_info[2]))\n",
    "        w = int(float(per_data_info[3]))\n",
    "        h = int(float(per_data_info[4]))\n",
    "            \n",
    "        folder_path = os.path.join(image_dir, folder_name)\n",
    "\n",
    "        for filename in glob.glob(folder_path + '\\*.jpg'):\n",
    "            length = len(img_name)\n",
    "            filename_short=filename[len(filename)-length:]\n",
    "                \n",
    "            if(filename_short == img_name):\n",
    "                img = cv2.imread(folder_path + '\\\\' + img_name)\n",
    "                img_height, img_width = img.shape[:2]\n",
    "            \n",
    "                x = int(x * 256 / img_width) \n",
    "                y = int(y * 256 / img_height)\n",
    "                w = int(w * 256 / img_width)\n",
    "                h = int(h * 256 / img_height)\n",
    "                \n",
    "                cv2.imwrite(save_images_dir + '\\\\' + img_name, img)\n",
    "                \n",
    "                row = [img_name, x, y, w, h]\n",
    "                csv_data.append(row)\n",
    "\n",
    "    with open(save_csv, 'w', newline='') as csvFile:\n",
    "        writer = csv.writer(csvFile)\n",
    "        writer.writerows(csv_data)\n",
    "        \n",
    "    csvFile.close()\n",
    "\n",
    "\n",
    "def create_datasets_UMD(image_dir, anno_dir, save_dir, \n",
    "                        train_size=20_000, test_size=2_000): #16_000 + 4_000\n",
    "    \n",
    "    dataset = parse_UMD(image_dir, anno_dir, train_size, test_size)\n",
    "    \n",
    "    make_dir_if_not_exist(save_dir)\n",
    "    save_folder_train = os.path.join(save_dir, 'train')\n",
    "    make_dir_if_not_exist(save_folder_train)\n",
    "    save_folder_test = os.path.join(save_dir, 'test')\n",
    "    make_dir_if_not_exist(save_folder_test)\n",
    "    \n",
    "    save_train_csv = r'D:\\jupyter_projects\\Face Detection\\data\\umdfaces_batch3\\data_UMD\\trainLabels.csv'\n",
    "    save_test_csv = r'D:\\jupyter_projects\\Face Detection\\data\\umdfaces_batch3\\data_UMD\\testLabels.csv'\n",
    "    generate_images_and_csv(image_dir, save_folder_train, save_train_csv, dataset, 0, train_size)\n",
    "    generate_images_and_csv(image_dir, save_folder_test, save_test_csv, dataset, train_size, test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "500\n",
      "1000\n",
      "1500\n",
      "2000\n",
      "2500\n",
      "3000\n",
      "3500\n",
      "4000\n",
      "4500\n",
      "5000\n",
      "5500\n",
      "6000\n",
      "6500\n",
      "7000\n",
      "7500\n",
      "8000\n",
      "8500\n",
      "9000\n",
      "9500\n",
      "10000\n",
      "10500\n",
      "11000\n",
      "11500\n",
      "12000\n",
      "12500\n",
      "13000\n",
      "13500\n",
      "14000\n",
      "14500\n",
      "15000\n",
      "15500\n",
      "16000\n",
      "16500\n",
      "17000\n",
      "17500\n",
      "18000\n",
      "18500\n",
      "19000\n",
      "19500\n",
      "20000\n",
      "20500\n",
      "21000\n",
      "21500\n",
      "0\n",
      "500\n",
      "1000\n",
      "1500\n",
      "2000\n",
      "2500\n",
      "3000\n",
      "3500\n",
      "4000\n",
      "4500\n",
      "5000\n",
      "5500\n",
      "6000\n",
      "6500\n",
      "7000\n",
      "7500\n",
      "8000\n",
      "8500\n",
      "9000\n",
      "9500\n",
      "10000\n",
      "10500\n",
      "11000\n",
      "11500\n",
      "12000\n",
      "12500\n",
      "13000\n",
      "13500\n",
      "14000\n",
      "14500\n",
      "15000\n",
      "15500\n",
      "16000\n",
      "16500\n",
      "17000\n",
      "17500\n",
      "18000\n",
      "18500\n",
      "19000\n",
      "19500\n",
      "20000\n",
      "20500\n",
      "21000\n",
      "21500\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    image_dir = r'D:\\jupyter_projects\\Face Detection\\data\\umdfaces_batch3\\data_UMD\\original_pics'\n",
    "    save_dir = r'D:\\jupyter_projects\\Face Detection\\data\\umdfaces_batch3\\data_UMD\\train_test'\n",
    "    anno_dir = r'D:\\jupyter_projects\\Face Detection\\data\\umdfaces_batch3\\data_UMD\\Annotation'\n",
    "    \n",
    "    create_datasets_UMD(image_dir, anno_dir, save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_csv(csv_dir, new_csv_dir):\n",
    "    csvfile = open(csv_dir) \n",
    "    new_csv = open(new_csv_dir, 'w', newline='')\n",
    "    \n",
    "    reader = csv.reader(csvfile, delimiter=',')\n",
    "    writer = csv.writer(new_csv)\n",
    "    \n",
    "    next(reader)\n",
    "    writer.writerow(['id', 'x1', 'y1', 'x2', 'y2'])\n",
    "    for row in reader:\n",
    "        img_name = row[0]\n",
    "        x = int(row[1])\n",
    "        y = int(row[2])\n",
    "        w = int(row[3])\n",
    "        h = int(row[4])\n",
    "        writer.writerow([img_name, str(x), str(y), str(x + w), str(y + h)])\n",
    "        \n",
    "    csvfile.close()\n",
    "    new_csv.close()\n",
    "            \n",
    "new_csv(r'D:\\jupyter_projects\\Face Detection\\data\\umdfaces_batch3\\data_UMD\\train_test\\testLabels.csv', \n",
    "       r'D:\\jupyter_projects\\Face Detection\\data\\umdfaces_batch3\\data_UMD\\train_test\\test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_csv(r'D:\\jupyter_projects\\Face Detection\\data\\umdfaces_batch3\\data_UMD\\train_test\\trainLabels.csv', \n",
    "       r'D:\\jupyter_projects\\Face Detection\\data\\umdfaces_batch3\\data_UMD\\train_test\\train.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
