# face_detection_with_CNNs
Решение задачи поиска лица на изображении на основе свёрточных нейронных сетей.
## Постановка задачи 
#### Дано:
RGB-изображение произвольного размера с одним, вариативным по положению, лицом на нём.
#### Требуется:
Построить функцию F, которая по массиву пикселей изображения сможет выделять лица на нём, а именно строить прямоугольную ограничительную рамку, внутри которой расположено лицо. Функция F возвращает координаты левой верхней и правой нижней вершины прямоугольной ограничительной рамки.

## Подготовка обучающей выборки
Существует множество размеченных наборов данных для распознавания лиц. В моей работе использовался набор данных [UMDFaces](https://www.umdfaces.io/) (Batch 3). Помимо ограничительных рамок, которые использовались в моей работе, UMDFaces предоставляет данные о расположении 21 ключевой точки лица, пол, сгенерированный предварительно обученной нейронной сетью, данные о положении лица (отклонение от нормали и др) и многое-многое другое.
![UMD Faces](https://github.com/Gumilevski/face_detection_with_CNNs/blob/master/images/2019-05-30_14-28-25.png)

Из всего набора данных было выделено 22 тысячи изображений для обучения и тестирования нейронных сетей. Из них 16 тысяч – train set (использовался для обучения нейронных сетей), 4 тысячи – validation set (использовался для подборки гиперпараметров моделей и предварительной оценки точности на данных, которые не видела нейронная сеть), остальные 2 тысячи – test set.

Изображения хранились в папках train и test, а ответы к ним - в csv-файлах train.csv и test.csv (подготовлены на основе umdfaces_batch3_ultraface.csv). В csv-файлах данные хранилась в виде название изображения (id-строка) и соответсвующие данному изображению ответы - координаты левой нижней и правой верхней вершин ограничительной рамки. 
В [данном скрипте](https://github.com/Gumilevski/face_detection_with_CNNs/blob/master/generating_script.ipynb) может быть найдена реализация подготовки обучающей выборки

## Описание первой модели ([CNN.ipynb](https://github.com/Gumilevski/face_detection_with_CNNs/blob/master/CNN.ipynb))
Теперь, когда обучающая выборка подготовлена, можем приступать к построению и обучению моделей.

Архитектура первой модели представлена на рисунке ниже:
![architecture 1](https://github.com/Gumilevski/face_detection_with_CNNs/blob/master/images/%D0%B0%D1%80%D1%85%D0%B8%D1%82%D0%B5%D0%BA%D1%82%D1%83%D1%80%D0%B0%201.png)

Графики ниже представлены для данных гиперпараметров:

Оптимизатор: Adam (lr = 6e-4)

Функция потерь: mse (средняя квадратичная ошибка)

Данная сеть обучалась на 60 эпохах, около 6 часов на GPU

![accuracy 1](https://github.com/Gumilevski/face_detection_with_CNNs/blob/master/images/2019-05-30_15-57-07.png)
![loss 1](https://github.com/Gumilevski/face_detection_with_CNNs/blob/master/images/2019-05-30_15-57-23.png)

Точность на тестовой выборке: 91.8 %

Пример работы модели:

![img 1](https://github.com/Gumilevski/face_detection_with_CNNs/blob/master/images/2019-05-30_16-02-31.png)

В CNN.ipynb представлен немного другой вариант обучения данной модели, на большем количестве эпох (100), соответственно в CNN.ipynb графики отличаются. Также в новой версии пока что нет проверки на тестовой выборке, так как еще планируется улучшать построенную модель.
Веса, полученные в рузультате обучения на 100 эпохах можно найти в папке Models_Weights (файл cnn.h5).

## Описание второй модели ([transfer_learning.ipynb](https://github.com/Gumilevski/face_detection_with_CNNs/blob/master/transfer_learning.ipynb))
Перейдём к описанию модели, построенной на основе переноса обучения и тонкой настройки.За базовую модель я взял архитектуру VGG-16, обученную на ImageNet’е. 

Опять же обращаю внимание, что в transfer_learning.ipynb гиперпараметры (а соответсвенно и графики) могут отличаться по сравнению с теми, что указаны ниже. Это опять же связано с тем, что вторая модель еще дорабатывается.

Итак, первый шаг - замена последних полносвязных слоёв VGG-16 на новые полносвязные слои, подходящие под нашу задачу:
![architecture 2](https://github.com/Gumilevski/face_detection_with_CNNs/blob/master/images/%D0%B0%D1%80%D1%85%D0%B8%D1%82%D0%B5%D0%BA%D1%82%D1%83%D1%80%D0%B02.png)

Шаг 2 - обучаем полносвязные слои на 15 эпохах - получаем точность около 82 %.
Оптимизатор: Adam (lr = 5e-5)
Функция потерь: mse (mean squared error)	

Шаг 3 - дообучаем последний, пятый свёрточный блок, процесс обучения сходится за 30 эпох.
Оптимизатор: Adam (lr = 1e-5)
Функция потерь: mse

![accuracy 2](https://github.com/Gumilevski/face_detection_with_CNNs/blob/master/images/2019-05-30_16-20-25.png)
![loss 2](https://github.com/Gumilevski/face_detection_with_CNNs/blob/master/images/2019-05-30_16-20-13.png)

В результате получаем точность на тестовой выборке: 89.7 %, а всё обучение длилось около 3 часов на GPU, что значительно меньше, чем в случае с первой моделью (6 часов). 

Как в случае и с первой моделью, в новой версии transfer_learning.ipynb пока что нет проверки на тестовой выборке, так как еще планируется улучшать построенную модель.
